{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Dec  3 23:19:18 2019\n",
    "\n",
    "@author: owgs (ghimsiong.ow@gmail.com)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import pandas as pd\n",
    "import re, string, time\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "class HMM(object):\n",
    "    '''\n",
    "    This HMM class comprises functions from two sources:\n",
    "    A) Nishant Shukla - Machine Learning with TensorFlow (2018, Manning Publications)\n",
    "       o used for implementing the forward algorithm\n",
    "       o used for implementing the Viterbi algorithm\n",
    "    B) Marvin Bertin - https://github.com/MarvinBertin/HiddenMarkovModel_TensorFlow\n",
    "       o used for implementing the Baum-Welch algorithm\n",
    "    '''    \n",
    "    \n",
    "    def __init__(self, initial_prob, trans_prob, obs_prob,\n",
    "                 epsilon=0.1, maxStep=5):\n",
    "        \n",
    "        T = trans_prob          # No need to convert as required format is the same.\n",
    "        E = obs_prob.T          # To convert the format from Source (A) to Source (B)\n",
    "        T0 = initial_prob.T[0]  # to convert to a row vector      \n",
    "        \n",
    "        with tf.name_scope('Inital_Parameters'):\n",
    "            with tf.name_scope('Scalar_constants'):\n",
    "                # Max number of iteration\n",
    "                self.maxStep = maxStep\n",
    "\n",
    "                # convergence criteria\n",
    "                self.epsilon = epsilon \n",
    "\n",
    "                # Number of possible states\n",
    "                self.S = T.shape[0]\n",
    "\n",
    "                # Number of possible observations\n",
    "                self.O = E.shape[0]\n",
    "                \n",
    "                self.prob_state_1 = []\n",
    "\n",
    "            with tf.name_scope('Model_Parameters'):\n",
    "                # Emission probability\n",
    "                self.E = tf.Variable(E, dtype=tf.float64, name='emission_matrix')\n",
    "\n",
    "                # Transition matrix\n",
    "                self.T = tf.Variable(T, dtype=tf.float64, name='transition_matrix')\n",
    "\n",
    "                # Initial state vector\n",
    "                self.T0 = tf.Variable(tf.constant(T0, dtype=tf.float64, name='inital_state_vector'))\n",
    "\t\t\n",
    "        \n",
    "\n",
    "    def initialize_forw_back_variables(self, shape):\n",
    "        self.forward = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='forward')\n",
    "        self.backward = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='backward')\n",
    "        self.posterior = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='posteriror')\n",
    "\n",
    "\n",
    "    def _forward(self, obs_prob_list):\n",
    "        \n",
    "        with tf.name_scope('init_scaling_factor'):\n",
    "            self.scale = tf.Variable(tf.zeros([self.N], tf.float64)) #scale factors\n",
    "        \n",
    "        with tf.name_scope('forward_first_step'):\n",
    "            # initialize with state starting priors\n",
    "            init_prob = tf.multiply(self.T0, tf.squeeze(obs_prob_list[0]))\n",
    "\n",
    "            # scaling factor at t=0\n",
    "            #owgs - self.scale = tf.scatter_update(self.scale, 0, 1.0 / tf.reduce_sum(init_prob))\n",
    "            self.scale = tf.scatter_update(self.scale, 0, 1.0 / tf.reduce_sum(init_prob))\n",
    "            \n",
    "            # scaled belief at t=0\n",
    "            #owgs self.forward = tf.scatter_update(self.forward, 0, self.scale[0] * init_prob)\n",
    "            self.forward = tf.scatter_update(self.forward, 0, self.scale[0] * init_prob)\n",
    "            \n",
    "        # propagate belief\n",
    "        for step, obs_prob in enumerate(obs_prob_list[1:]):\n",
    "            with tf.name_scope('time_step-%s' %step):\n",
    "                # previous state probability\n",
    "                prev_prob = tf.expand_dims(self.forward[step, :], 0)\n",
    "                # transition prior\n",
    "                prior_prob = tf.matmul(prev_prob, self.T)\n",
    "                # forward belief propagation\n",
    "                forward_score = tf.multiply(prior_prob, tf.squeeze(obs_prob))\n",
    "\n",
    "                forward_prob = tf.squeeze(forward_score)\n",
    "                # scaling factor\n",
    "                #owgs - self.scale = tf.scatter_update(self.scale, step+1, 1.0 / tf.reduce_sum(forward_prob))\n",
    "                self.scale = tf.scatter_update(self.scale, step+1, 1.0 / tf.reduce_sum(forward_prob))\n",
    "                \n",
    "                # Update forward matrix\n",
    "                #owgs - self.forward = tf.scatter_update(self.forward, step+1, self.scale[step+1] * forward_prob)\n",
    "                self.forward = tf.scatter_update(self.forward, step+1, self.scale[step+1] * forward_prob)\n",
    "        \n",
    "\n",
    "    def _backward(self, obs_prob_list):\n",
    "        with tf.name_scope('backward_last_step'):\n",
    "            # initialize with state ending priors\n",
    "            #owgs self.backward = tf.scatter_update(self.backward, 0, self.scale[self.N-1] * tf.ones([self.S], dtype=tf.float64)) \n",
    "            self.backward = tf.scatter_update(self.backward, 0, self.scale[self.N-1] * tf.ones([self.S], dtype=tf.float64)) \n",
    "\n",
    "        # propagate belief\n",
    "        for step, obs_prob in enumerate(obs_prob_list[:-1]):\n",
    "            with tf.name_scope('time_step-%s' %step):\n",
    "                # next state probability\n",
    "                next_prob = tf.expand_dims(self.backward[step, :], 1)\n",
    "                # observation emission probabilities\n",
    "                obs_prob_d = tf.linalg.tensor_diag(tf.squeeze(obs_prob)) #owgs - tf.diag(tf.squeeze(obs_prob))\n",
    "                # transition prior\n",
    "                prior_prob = tf.matmul(self.T, obs_prob_d)\n",
    "                # backward belief propagation\n",
    "                backward_score = tf.matmul(prior_prob, next_prob)\n",
    "\n",
    "                backward_prob = tf.squeeze(backward_score)\n",
    "\n",
    "                # Update backward matrix\n",
    "                #owgs self.backward = tf.scatter_update(self.backward, step+1, self.scale[self.N-2-step] * backward_prob)\n",
    "                self.backward = tf.scatter_update(self.backward, step+1, self.scale[self.N-2-step] * backward_prob)\n",
    "        \n",
    "        self.backward = tf.assign(self.backward, tf.reverse(self.backward, [True, False])) #owgs- tf.assign(self.backward, tf.reverse(self.backward, [True, False]))\n",
    "\n",
    "        \n",
    "    def _posterior(self):\n",
    "        # posterior score\n",
    "        self.posterior = tf.multiply(self.forward, self.backward)\n",
    "\n",
    "        marginal = tf.reduce_sum(self.posterior, 1)\n",
    "        self.posterior = self.posterior / tf.expand_dims(marginal, 1)       \n",
    "        \n",
    "        \n",
    "    def re_estimate_emission(self, x):\n",
    "        \n",
    "        states_marginal = tf.reduce_sum(self.gamma, 0)\n",
    "        seq_one_hot = tf.one_hot(tf.cast(x, tf.int64), self.O, 1, 0)\n",
    "        emission_score = tf.matmul(tf.cast(seq_one_hot, tf.float64), self.gamma, transpose_a=True)\n",
    "        return emission_score / states_marginal\n",
    "    \n",
    "    def re_estimate_transition(self, x):\n",
    "        \n",
    "        with tf.name_scope('Init_3D_tensor'):\n",
    "            self.M = tf.Variable(tf.zeros((self.N-1, self.S, self.S), tf.float64))\n",
    "        \n",
    "        with tf.name_scope('3D_tensor_transition'):\n",
    "            for t in range(self.N - 1):\n",
    "                with tf.name_scope('time_step-%s' %t):\n",
    "                    tmp_0 = tf.matmul(tf.expand_dims(self.forward[t, :], 0), self.T)\n",
    "                    tmp_1 = tf.multiply(tmp_0, tf.expand_dims(tf.gather(self.E, x[t+1]), 0))\n",
    "                    denom = tf.squeeze(tf.matmul(tmp_1, tf.expand_dims(self.backward[t+1, :], 1)))\n",
    "\n",
    "                with tf.name_scope('Init_new_transition'):\n",
    "                    trans_re_estimate = tf.Variable(tf.zeros((self.S, self.S), tf.float64))\n",
    "                    \n",
    "                for i in range(self.S):\n",
    "                    with tf.name_scope('State-%s' %i):\n",
    "                        numer = self.forward[t, i] * self.T[i, :] * tf.gather(self.E, x[t+1]) * self.backward[t+1, :]\n",
    "                        #owgs trans_re_estimate = tf.scatter_update(trans_re_estimate, i, numer / denom)\n",
    "                        trans_re_estimate = tf.scatter_update(trans_re_estimate, i, numer / denom)\n",
    "                        \n",
    "                #self.M = tf.scatter_update(self.M, t, trans_re_estimate)\n",
    "                self.M = tf.scatter_update(self.M, t, trans_re_estimate)\n",
    "\n",
    "        with tf.name_scope('Smooth_gamma'):\n",
    "            self.gamma = tf.squeeze(tf.reduce_sum(self.M, 2))\n",
    "            T_new = tf.reduce_sum(self.M, 0) / tf.expand_dims(tf.reduce_sum(self.gamma, 0), 1)\n",
    "        \n",
    "        with tf.name_scope('New_init_states_prob'):\n",
    "            T0_new = self.gamma[0,:]\n",
    "\n",
    "        with tf.name_scope('Append_gamma_final_time_step'):\n",
    "            prod = tf.expand_dims(tf.multiply(self.forward[self.N-1, :], self.backward[self.N-1, :]), 0)\n",
    "            s= prod/ tf.reduce_sum(prod)\n",
    "            self.gamma = tf.concat([self.gamma, s], 0)\n",
    "            \n",
    "            self.prob_state_1.append(self.gamma[:, 0])\n",
    "        \n",
    "        return T0_new, T_new\n",
    "    \n",
    "    def check_convergence(self, new_T0, new_transition, new_emission):\n",
    "        \n",
    "        delta_T0 = tf.reduce_max(tf.abs(self.T0 - new_T0)) < self.epsilon\n",
    "        delta_T = tf.reduce_max(tf.abs(self.T - new_transition)) < self.epsilon\n",
    "        delta_E = tf.reduce_max(tf.abs(self.E - new_emission)) < self.epsilon\n",
    "\n",
    "        return tf.logical_and(tf.logical_and(delta_T0, delta_T), delta_E)\n",
    "        \n",
    "    def forward_backward(self, obs_prob_seq):\n",
    "        obs_prob_list_for = tf.split(obs_prob_seq, self.N, 0)\n",
    "        \n",
    "        with tf.name_scope('forward_belief_propagation'):\n",
    "            # forward belief propagation\n",
    "            self._forward(obs_prob_list_for)\n",
    "\n",
    "        obs_prob_seq_rev = tf.reverse(obs_prob_seq, [True, False])\n",
    "        obs_prob_list_back = tf.split(obs_prob_seq_rev, self.N, 0)\n",
    "\n",
    "        with tf.name_scope('backward_belief_propagation'):\n",
    "            # backward belief propagation\n",
    "            self._backward(obs_prob_list_back)\n",
    "        \n",
    "    def expectation_maximization_step(self, x):\n",
    "        \n",
    "        # probability of emission sequence\n",
    "        obs_prob_seq = tf.gather(self.E, x)\n",
    "\n",
    "        with tf.name_scope('Forward_Backward'):\n",
    "            self.forward_backward(obs_prob_seq)\n",
    "\n",
    "        with tf.name_scope('Re_estimate_transition'):\n",
    "            new_T0, new_transition = self.re_estimate_transition(x)\n",
    "        \n",
    "        with tf.name_scope('Re_estimate_emission'):\n",
    "            new_emission = self.re_estimate_emission(x)\n",
    "\n",
    "        with tf.name_scope('Check_Convergence'):\n",
    "            converged = self.check_convergence(new_T0, new_transition, new_emission)\n",
    "\n",
    "        with tf.name_scope('Update_parameters'):\n",
    "            self.T0 = tf.assign(self.T0, new_T0)\n",
    "            self.E = tf.assign(self.E, new_emission)\n",
    "            self.T = tf.assign(self.T, new_transition)\n",
    "            #self.count = tf.assign_add(self.count, 1)\n",
    "             \n",
    "            with tf.name_scope('histogram_summary'):\n",
    "                _ = tf.summary.histogram(self.T0.name, self.T0) #owgs - tf.summary.histogram(self.T0.name, self.T0)\n",
    "                _ = tf.summary.histogram(self.T.name, self.T) #owgs - tf.summary.histogram(self.T.name, self.T)\n",
    "                _ = tf.summary.histogram(self.E.name, self.E) #owgs - tf.summary.histogram(self.E.name, self.E)\n",
    "        return converged\n",
    "        \n",
    "    \n",
    "    def Baum_Welch_EM(self, obs_seq):\n",
    "        \n",
    "        with tf.name_scope('Input_Observed_Sequence'):\n",
    "            # length of observed sequence\n",
    "            self.N = len(obs_seq)\n",
    "\n",
    "            # shape of Variables\n",
    "            shape = [self.N, self.S]\n",
    "\n",
    "            # observed sequence\n",
    "            x = tf.constant(obs_seq, dtype=tf.int32, name='observation_sequence')\n",
    "        \n",
    "        with tf.name_scope('Initialize_variables'):\n",
    "            # initialize variables\n",
    "            self.initialize_forw_back_variables(shape)\n",
    "        \n",
    "        converged = tf.cast(False, tf.bool)\n",
    "        #self.count = tf.Variable(tf.constant(0))\n",
    "        \n",
    "        with tf.name_scope('Train_Baum_Welch'):\n",
    "            for i in range(self.maxStep):\n",
    "                \n",
    "                with tf.name_scope('EM_step-%s' %i):\n",
    "                    converged = self.expectation_maximization_step(x)\n",
    "      \n",
    "        return converged\n",
    "              \n",
    "def run_Baum_Welch_EM(sess, hmm, obs_seq, summary=False, monitor_state_1=False):\n",
    "    \n",
    "    converged = hmm.Baum_Welch_EM(obs_seq)\n",
    "    \n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.summary.merge_all() #owgs - tf.summary.merge_all()\n",
    "    \n",
    "    # Run \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    trans0, transition, emission, c = sess.run([hmm.T0, hmm.T, hmm.E, converged])\n",
    "\n",
    "    return trans0, transition, emission, c    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "fp = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalise the session\n",
    "sess = tf.Session()\n",
    "     \n",
    "# Load and prepare the data\n",
    "fp = \"text.txt\"\n",
    "s = open(fp).read()[:10000]\n",
    "s2 = re.sub(\"[^a-z]\", \"_\", s.lower())\n",
    "    \n",
    "# Prepare the dataframe of data\n",
    "alpha_states = [\"_\"] + list(string.ascii_lowercase)\n",
    "mapper = dict(zip(alpha_states, range(len(alpha_states))))\n",
    "V = pd.Series(list(s2)).map(mapper).values\n",
    "data = pd.DataFrame({\"Visible\": V, \"Alphabet\": list(s2)})\n",
    "data[\"Hidden\"] = data[\"Alphabet\"].map({\"a\": 1, \"e\": 1, \"i\": 1, \"o\": 1, \"u\": 1}).replace(np.nan, 0).astype(int)\n",
    "data = data[[\"Alphabet\", \"Hidden\", \"Visible\"]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial distributions\n",
    "initial_distribution = np.array([[0.6],[0.4]])\n",
    "initial_T = np.array([[0.6177499,0.3822501], [0.8826096,0.1173904]])\n",
    "initial_E = np.array([\n",
    "            [0.037192964,0.009902360,0.032833978,0.044882670,0.057331132,\n",
    "             0.052143890,0.013665015,0.036187536,0.072293323,0.044793972,0.060008388,\n",
    "             0.004256270,0.024770706,0.053520546,0.014232306,0.046981769,0.053733382,\n",
    "             0.066355203,0.046817817,0.006912535,0.016201697,0.013425499,0.024694447,\n",
    "             0.064902148,0.046170421,0.033586536,0.022203489],\n",
    "            [0.0389931197,0.0697183142,0.0239154174,0.0512772632,0.0404732634,0.0059687348,\n",
    "             0.0211687193,0.0625229746,0.0039632091,0.0567828864,0.0468108656,0.0168355418,\n",
    "             0.0627882213,0.0286478204,0.0389215263,0.0064318198,0.0001698078,0.0493758725,\n",
    "             0.0652709152,0.0069580806,0.0093043072,0.0028807932,0.0521827110,0.0608822385,\n",
    "             0.0645417465,0.0555249876,0.0576888424]\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chars = 100\n",
    "maxStep = 2\n",
    "\n",
    "# Start logs\n",
    "print (\"Start time: %s\" % time.asctime())\n",
    "start_time = time.perf_counter()\n",
    "            \n",
    "# Initialise the model\n",
    "hmm =  HMM(initial_distribution, initial_T, initial_E,epsilon=0.1, maxStep=maxStep)\n",
    "            \n",
    "# Run the baum welch algorithm\n",
    "trans0, transition, emission, c = run_Baum_Welch_EM(\n",
    "                sess, hmm,\n",
    "                data[\"Visible\"].values[:num_chars], summary=False, monitor_state_1=True)       \n",
    "        \n",
    "# End logs\n",
    "print (\"End time: %s\" % time.asctime())\n",
    "end_time = time.perf_counter()\n",
    "print (\"Time taken: %s hrs\" % ((end_time-start_time)/60/60))\n",
    "        \n",
    "print(\"Transition Matrix: \")\n",
    "print(transition)\n",
    "print()\n",
    "print(\"Emission Matrix: \")\n",
    "print(emission)\n",
    "print()\n",
    "print(\"Reached Convergence: \")\n",
    "print(c) \n",
    "    \n",
    "# plot\n",
    "plt.bar(alpha_states, emission[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
