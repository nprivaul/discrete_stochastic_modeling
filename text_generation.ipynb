{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize trans:  0.0068019230384379625\n",
      "make trans matrix:  0.06976865301840007\n",
      "empty:  312481911\n",
      "nonempty:  18089\n",
      "normalize trans:  0.17397999000968412\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Markov Chain Text Generation Project\n",
    "Michael Shan Wang\n",
    "\"\"\"\n",
    "\n",
    "####################\n",
    "#SET CONSTANTS BELOW\n",
    "####################\n",
    "\n",
    "ORDER = 5 #The order: length of character strings that comprise state space\n",
    "OUTLEN = 1000 #Number of characters in the output string\n",
    "\n",
    "####################\n",
    "####################\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from time import perf_counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Read input text file\n",
    "with open('my_own_text_file.txt') as f: #Change to your own text file if you have\n",
    "    train = f.read()\n",
    "    \n",
    "#Process the text string\n",
    "train=train.lower() #converts letters to lowercase\n",
    "train=re.sub('\\s', ' ', train) #converts all whitespaces to normal spaces\n",
    "train=re.sub('[^a-z0-9&?\\'-:,()\\\"!;. ]', '', train) #deletes all characters that are not alphanumeric or certain punctuation or whitespaces\n",
    "\n",
    "#Check characters in file\n",
    "unique=set(train) #contains set of all unique characters in input text\n",
    "#print(unique)\n",
    "unique=sorted(unique)\n",
    "n=len(unique) #n is number of characters we are considering in our alphabet\n",
    "mapping={unique[i]:i for i in range(n)} #maps each character to an integer index\n",
    "#print(mapping)\n",
    "\n",
    "#Get base rates of character occurences\n",
    "base=np.zeros(n)\n",
    "for i in range(len(train)):\n",
    "    base[mapping[train[i]]]+=1\n",
    "for i in range(n):\n",
    "    base[i]/=len(train)\n",
    "#print(base)\n",
    "\n",
    "#Create transition matrix\n",
    "#For text generation, traditional square transition matrix will be mostly 0\n",
    "#To save space we use non-square\n",
    "start=perf_counter()\n",
    "numstates=n**ORDER #numstates is number of possible substrings in state space\n",
    "trans=dict() #empty dictionary but in theory it is equivalent to numstates by n matrix\n",
    "stop=perf_counter()\n",
    "print(\"initialize trans: \", stop-start)\n",
    "\n",
    "#Compute transition matrix from input text\n",
    "#Increments the appropriate transition element for each character transition in input text\n",
    "start=perf_counter()\n",
    "for i in range(ORDER, len(train)):\n",
    "    prev=train[i-ORDER:i]\n",
    "    if prev not in trans.keys(): trans[prev]=[0]*n #for unseen character string, initialize new row in trans\n",
    "    nextchar=train[i]\n",
    "    trans[prev][mapping[nextchar]]+=1\n",
    "stop=perf_counter()\n",
    "print(\"make trans matrix: \", stop-start)\n",
    "start=perf_counter()\n",
    "\n",
    "#make rows of trans sum to one\n",
    "for i in trans.keys():\n",
    "    total=0\n",
    "    for j in range(n): total+=trans[i][j]\n",
    "    for j in range(n): trans[i][j]/=total\n",
    "print(\"empty: \", numstates-len(trans.keys())) #number of strings in state space not seen in input\n",
    "print(\"nonempty: \", len(trans.keys())) #number of strings in state space seen in input\n",
    "stop=perf_counter()\n",
    "print(\"normalize trans: \", stop-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e with the wouldnt know she laugh. john laugh. but i shall night, for a whim. i wasnt alone swamp our child and that john, and directly from all the does.  you are it is in my path.  im getting or copies of this provide volunteers and discovered arbors, creeping the vicious from outside the fainted on it out, and good.  but its originator of equal distributing that women do let the place! it does not say another on the yellow wallpaperwork (or by e-mail) with these numerous located with a laughs at me as if she wallow wallpaper.  the general terms will and creeping to not be linked to sulk about behind the front design, and rush off most received throughout paying odor i even if i could get more care took all license.  and disturb me as well say, at the project gutenberg-tm electronic work, or an hours included.  of course, what chair than there and keeping up and slowly, and then the bargain.  i got it, but the grotesque, reminding road this ebook.  author: charge a fee for a thing no\n",
      "generate output:  0.030359552998561412\n"
     ]
    }
   ],
   "source": [
    "#Generate output text starting from random individual characters\n",
    "#returns burnin time and the string output\n",
    "def makeoutput():\n",
    "    burnin=0 #We need burn in time because we start by generating output from random string of length ORDER\n",
    "    start=perf_counter()\n",
    "    output=[]\n",
    "    prev=\"\"\n",
    "    for i in range(ORDER): #generate ORDER characters according to base rates and update index\n",
    "        nextchar=np.random.choice(unique, p=base)\n",
    "        prev=prev+nextchar\n",
    "        output.append(nextchar)\n",
    "    first=True\n",
    "    i1=0 #total number of characters generated\n",
    "    i2=0 #number of characters generated towards output text\n",
    "    while i2 < OUTLEN: #generate rest of output text based on transition probabilities\n",
    "        if prev in trans.keys():\n",
    "            if first:\n",
    "                burnin=i1\n",
    "                first=False\n",
    "            nextchar=np.random.choice(unique, p=trans[prev])\n",
    "            output.append(nextchar)\n",
    "            i2+=1\n",
    "        else: nextchar=np.random.choice(unique, p=base)\n",
    "        prev=prev+nextchar\n",
    "        prev=prev[1:]\n",
    "        i1+=1\n",
    "    stroutput=''.join(output)\n",
    "    stroutput=stroutput[-OUTLEN:] #remove burnin part of string\n",
    "    stop=perf_counter()\n",
    "    print(\"generate output: \", stop-start)\n",
    "    return burnin, stroutput\n",
    "\n",
    "\n",
    "\n",
    "#The new more efficient variation of makeoutput, without random characters at first\n",
    "start=perf_counter()\n",
    "output=[]\n",
    "prev=np.random.choice(list(trans.keys()))\n",
    "i1=0\n",
    "i2=0\n",
    "while i2 < OUTLEN:\n",
    "    if prev in trans.keys():\n",
    "        nextchar=np.random.choice(unique, p=trans[prev])\n",
    "        output.append(nextchar)\n",
    "        i2+=1\n",
    "    else: nextchar=np.random.choice(unique, p=base)\n",
    "    prev=prev+nextchar\n",
    "    prev=prev[1:]\n",
    "    i1+=1\n",
    "stroutput=''.join(output)\n",
    "stroutput=stroutput[-OUTLEN:]\n",
    "stop=perf_counter()\n",
    "print(stroutput)\n",
    "print(\"generate output: \", stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
